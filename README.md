# Amazon Rekognition Face Detection using Video Stream

## Architecture Overview
![Alt text](https://d195kho0tyqjph.cloudfront.net/Arquitetura-Blogpost.drawio.png "Solution Overview")

Facial Recognition System Overview

Data Storage Pipeline: This component handles the storage of two types of data. Firstly, it manages the storage of a collection of faces (Bucket 1) that are designated for recognition during video streaming. Secondly, it stores the metadata output generated by Amazon Rekognition (Bucket 2), which is crucial for auditing purposes.

Video Processing Pipeline: This pipeline begins once video streams are transmitted through the Amazon Kinesis Video Streams API, accessed via the Video Stream endpoint. It supports input from various sources, such as RTSP cameras (e.g., Raspberry Pi-based setups) and desktop webcams. Amazon Rekognition analyzes these streams in real-time. AWS Lambda 1 is responsible for processing Rekognition's outputs, triggering subsequent actions in response to recognized faces.

Notification and Reporting Pipeline: Upon recognition events, this pipeline handles the generation of notifications. AWS Lambda 1 sends messages to an Amazon SQS queue, activating AWS Lambda 2. Lambda 2 then utilizes APIs of messaging platforms, like Amazon SES or others (e.g., Slack, WhatsApp), to deliver notifications to designated recipients. This component ensures timely alerts and facilitates integration with diverse messaging applications for effective communication.

## Pre-requisites
* AWS [CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html) with [credentials configured](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html) which will also be used by the CDK.
* Create and source a Python virtualenv on MacOS and Linux, and install python dependencies: 
<pre><code>python3 -m venv .env
source .env/bin/activate
pip install -r requirements.txt
</code></pre>

* Install the latest version of the AWS [CDK](https://docs.aws.amazon.com/cdk/v2/guide/getting_started.html) CLI:
<pre><code>npm i -g aws-cdk</code></pre>
* [Bootstrapping](https://docs.aws.amazon.com/cdk/v2/guide/bootstrapping.html) your CDK with:
<pre><code>cdk bootstrap</code></pre>

## Running
Make sure you have AWS CDK installed and working, all the dependencies of this project defiend in the requirements.txt file, and make sure you are runnning on US East (N. Virginia) region or other region that Amazon Rekognition Video streaming API is available. You can check [here](https://docs.aws.amazon.com/general/latest/gr/rekognition.html)


1.
<pre><code>git clone https://github.com/aws-samples/amazon-rekognition-face-detection-video-stream
cd iac
</code></pre>
2. Run <code>cdk deploy</code> and wait for the deployment to finish successfully;

## Testing
1. Open your AWS Console and go to AWS S3 Service and go to the bucket faces-collection-<some randon ID>
2. Upload a photo of yourself (make sure to upload a JPG file)
3. Create a tag for the photo you have just uploaded, on Key field please put the same name of the object (please, don't forget to put the objecet name with the ".jpg" extension) and on the Value field put the name of the person recognized - this step is for resolve desambiguity, in case you upload of 2+ photos of the same person on your dataset.
4. Go to Amazon SES service and create identity, on Identity type choose "Email address" and put your own email, click on "Create Identity". After this go to your inbox email and authorize AWS to send emails.
5. Now go to your terminal and run the following command to start the stream processor you created.
<pre><code>aws rekognition start-stream-processor --name stream-video-rekognition-processor</code></pre>
6. Start stream to your video stream that you just created - MyDataStream. You can use [Amazon Kinesis Video Streams Producer SDK](https://github.com/awslabs/amazon-kinesis-video-streams-producer-sdk-cpp#building-from-source) from the AWS Labs GitHub repository, that includes various ways of writing to a Kinesis Video Stream. These include native SDKs, a gstreamer application that uses the webcam on your Mac or PC, a Raspberry Pi project, and other methods.

$ gst-launch-1.0 autovideosrc ! videoconvert ! video/x-raw,format=I420,width=640,height=480,framerate=30/1 ! vtenc_h264_hw allow-frame-reordering=FALSE realtime=TRUE max-keyframe-interval=45 bitrate=1000 ! h264parse ! video/x-h264,stream-format=avc,alignment=au,profile=baseline ! kvssink stream-name=MyVideoStream-jghGnG3iheHb storage-size=128 access-key="AKIAQAQI5HPOV" secret-key="ic/qb3m7woo70ONJQiUO2efgddgwJ"

Run the following command to start the webcam from you MAC.

Command for RTSP camera

gst-launch-1.0 rtspsrc location="rtsp://temp:Iipl@123@182.156.1.58:6036/cam/realmonitor?channel=1&subtype=0" short-header=TRUE ! rtph264depay ! h264parse ! kvssink stream-name=MyVideoStream-oQE9Keh1Sp1o storage-size=128 access-key="" secret-key="


## Cleaning Up
Open your terminal on the root of the clone repository and these commands:
<pre><code>cd iac
cdk destroy
</code></pre>

